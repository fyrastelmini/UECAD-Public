{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "models=[\"mlp\",\"cnn\",\"lstm\"]\n",
    "columns=[\"readings\",\"cycle\",\"trend\"]\n",
    "files_train=os.listdir(\"dataset/train\")\n",
    "files_test=os.listdir(\"dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['filled']=df['meter_reading'].apply(lambda x: 0)\n",
    "    existing_hours = df['timestamp'].dt.floor('H').unique()\n",
    "    \n",
    "    start_date = df['timestamp'].min().replace(minute=0, second=0)\n",
    "    end_date = df['timestamp'].max().replace(minute=0, second=0)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "    all_hours_present = all(hour in existing_hours for hour in date_range)\n",
    "    if not(all_hours_present):\n",
    "        complete_df = pd.DataFrame({'timestamp': date_range})\n",
    "        df = complete_df.merge(df, on='timestamp', how='left')\n",
    "        df['filled']=df['filled'].fillna(1)\n",
    "        df['meter_reading'] = df['meter_reading'].interpolate(method='linear', limit_direction='both')\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "    #apply minmax scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['meter_reading'] = scaler.fit_transform(df['meter_reading'].values.reshape(-1,1))\n",
    "    grouped_df = df.groupby(df['timestamp'].dt.date)\n",
    "    \n",
    "    # Aggregate 'meter_reading' values into a list for each day\n",
    "    aggregated_df = grouped_df.agg({'meter_reading': list, 'anomaly': list, 'filled':list}).reset_index()\n",
    "\n",
    "    # Rename columns and sort by date\n",
    "    aggregated_df.columns = ['date', 'readings', 'anomalies','filled']\n",
    "    aggregated_df = aggregated_df.sort_values(by='date')\n",
    "\n",
    "    # Display the aggregated dataframe\n",
    "    aggregated_df[\"length\"] = aggregated_df[\"readings\"].apply(lambda lst: len([x for x in lst if not pd.isna(x)]))\n",
    "    aggregated_df[\"no_anomalies\"] = aggregated_df[\"anomalies\"].apply(lambda x: True if all(val == 0 for val in x) else False)\n",
    "    aggregated_df[\"filled\"] = aggregated_df[\"filled\"].apply(lambda x: False if all(val == 0 for val in x) else True)\n",
    "\n",
    "\n",
    "    df=aggregated_df[aggregated_df[\"length\"]==24]\n",
    "    df['cycle'] = df[\"readings\"].apply(lambda x: sm.tsa.filters.hpfilter(x, 2)[0])\n",
    "    df['trend'] = df[\"readings\"].apply(lambda x: sm.tsa.filters.hpfilter(x, 2)[1])\n",
    "    df[\"months\"] = df[\"date\"].apply(lambda x: str(x.month))\n",
    "    df[\"weekday\"] = df[\"date\"].apply(lambda x: str(x.weekday()))\n",
    "    df[\"weekend\"] = df[\"weekday\"].apply(lambda x: 1 if x in [\"5\",\"6\"] else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_datasets=[]\n",
    "test_datasets=[]\n",
    "\n",
    "for file in files_train:\n",
    "    dataset=pd.read_csv(\"dataset/train/\"+file)\n",
    "    train_dataset=prepare_dataset(dataset)\n",
    "    train_datasets.append(train_dataset)\n",
    "for file in files_test:\n",
    "    dataset=pd.read_csv(\"dataset/test/\"+file)\n",
    "    test_dataset=prepare_dataset(dataset)\n",
    "    test_datasets.append(test_dataset)\n",
    "# concatenate all the csv files into one\n",
    "train_dataset= pd.concat(train_datasets)\n",
    "test_dataset= pd.concat(test_datasets)\n",
    "\n",
    "train_dataset=train_dataset[train_dataset[\"filled\"]==0]\n",
    "test_dataset=test_dataset[test_dataset[\"filled\"]==0]\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>readings</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>filled</th>\n",
       "      <th>length</th>\n",
       "      <th>no_anomalies</th>\n",
       "      <th>cycle</th>\n",
       "      <th>trend</th>\n",
       "      <th>months</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>[0.4949748743718593, 0.5678391959798995, 0.522...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.03123344778510584, 0.03941239826478582, 0....</td>\n",
       "      <td>[0.5262083221569651, 0.5284267977151137, 0.515...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>[0.4396984924623116, 0.4271356783919598, 0.487...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0018269408516842778, -0.021690685703229518,...</td>\n",
       "      <td>[0.4378715516106273, 0.44882636409518933, 0.46...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>[0.41959798994974873, 0.4396984924623116, 0.52...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.009053880414004123, -0.01316737908346971, ...</td>\n",
       "      <td>[0.42865187036375285, 0.4528658715457813, 0.47...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>[0.42462311557788945, 0.4296482412060301, 0.42...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.0003693508051154648, 0.0022657521224360155...</td>\n",
       "      <td>[0.4249924663830049, 0.4273824890835941, 0.429...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>[0.5477386934673367, 0.5402010050251257, 0.545...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.0027492076873769644, -0.004783365280123131...</td>\n",
       "      <td>[0.5504879011547137, 0.5449843703052488, 0.538...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>[0.4570536179073399, 0.43987506507027585, 0.44...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.005837027211260448, -0.006189871875762865, ...</td>\n",
       "      <td>[0.45121659069607944, 0.4460649369460387, 0.44...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>[0.43102550754815194, 0.43987506507027585, 0.4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.0017604949444661733, 0.00811677003408795, ...</td>\n",
       "      <td>[0.4327860024926181, 0.4317582950361879, 0.429...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>[0.44351900052056215, 0.4242581988547631, 0.42...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.005938749745207805, -0.00670914850011195, 0...</td>\n",
       "      <td>[0.43758025077535434, 0.4309673473548751, 0.42...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>[0.4263404476834982, 0.4299843831337845, 0.436...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.0009624783530313152, 0.0003953337661932177...</td>\n",
       "      <td>[0.42730292603652953, 0.4295890493675913, 0.43...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>[0.41644976574700676, 0.4320666319625195, 0.43...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.005760389947572386, 0.006683603317661713, ...</td>\n",
       "      <td>[0.42221015569457915, 0.4253830286448578, 0.42...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                           readings  \\\n",
       "0    2016-01-01  [0.4949748743718593, 0.5678391959798995, 0.522...   \n",
       "1    2016-01-02  [0.4396984924623116, 0.4271356783919598, 0.487...   \n",
       "2    2016-01-03  [0.41959798994974873, 0.4396984924623116, 0.52...   \n",
       "3    2016-01-04  [0.42462311557788945, 0.4296482412060301, 0.42...   \n",
       "4    2016-01-05  [0.5477386934673367, 0.5402010050251257, 0.545...   \n",
       "..          ...                                                ...   \n",
       "361  2016-12-27  [0.4570536179073399, 0.43987506507027585, 0.44...   \n",
       "362  2016-12-28  [0.43102550754815194, 0.43987506507027585, 0.4...   \n",
       "363  2016-12-29  [0.44351900052056215, 0.4242581988547631, 0.42...   \n",
       "364  2016-12-30  [0.4263404476834982, 0.4299843831337845, 0.436...   \n",
       "365  2016-12-31  [0.41644976574700676, 0.4320666319625195, 0.43...   \n",
       "\n",
       "                                             anomalies  filled  length  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "..                                                 ...     ...     ...   \n",
       "361  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "362  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "363  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "364  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "365  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   False      24   \n",
       "\n",
       "     no_anomalies                                              cycle  \\\n",
       "0            True  [-0.03123344778510584, 0.03941239826478582, 0....   \n",
       "1            True  [0.0018269408516842778, -0.021690685703229518,...   \n",
       "2            True  [-0.009053880414004123, -0.01316737908346971, ...   \n",
       "3            True  [-0.0003693508051154648, 0.0022657521224360155...   \n",
       "4            True  [-0.0027492076873769644, -0.004783365280123131...   \n",
       "..            ...                                                ...   \n",
       "361          True  [0.005837027211260448, -0.006189871875762865, ...   \n",
       "362          True  [-0.0017604949444661733, 0.00811677003408795, ...   \n",
       "363          True  [0.005938749745207805, -0.00670914850011195, 0...   \n",
       "364          True  [-0.0009624783530313152, 0.0003953337661932177...   \n",
       "365          True  [-0.005760389947572386, 0.006683603317661713, ...   \n",
       "\n",
       "                                                 trend months weekday  weekend  \n",
       "0    [0.5262083221569651, 0.5284267977151137, 0.515...      1       4        0  \n",
       "1    [0.4378715516106273, 0.44882636409518933, 0.46...      1       5        1  \n",
       "2    [0.42865187036375285, 0.4528658715457813, 0.47...      1       6        1  \n",
       "3    [0.4249924663830049, 0.4273824890835941, 0.429...      1       0        0  \n",
       "4    [0.5504879011547137, 0.5449843703052488, 0.538...      1       1        0  \n",
       "..                                                 ...    ...     ...      ...  \n",
       "361  [0.45121659069607944, 0.4460649369460387, 0.44...     12       1        0  \n",
       "362  [0.4327860024926181, 0.4317582950361879, 0.429...     12       2        0  \n",
       "363  [0.43758025077535434, 0.4309673473548751, 0.42...     12       3        0  \n",
       "364  [0.42730292603652953, 0.4295890493675913, 0.43...     12       4        0  \n",
       "365  [0.42221015569457915, 0.4253830286448578, 0.42...     12       5        1  \n",
       "\n",
       "[1461 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def make_numpy(column):\n",
    "    dataset=np.array([np.array(i) for i in column])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=make_numpy(train_dataset[\"readings\"])\n",
    "y_train=train_dataset[\"no_anomalies\"].astype(float).values\n",
    "X_test=make_numpy(test_dataset[\"readings\"])\n",
    "y_test=test_dataset[\"no_anomalies\"].astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cynthia/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    " \n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    " \n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(24, 24)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(24, 24)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(24, 24)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(24, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m targets \u001b[39m=\u001b[39m y_batch\n\u001b[1;32m      2\u001b[0m \u001b[39m# Calculate the class weights based on the class distribution\u001b[39;00m\n\u001b[1;32m      3\u001b[0m total_samples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(targets)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_batch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "targets = y_batch\n",
    "# Calculate the class weights based on the class distribution\n",
    "total_samples = len(targets)\n",
    "epsilon = 1e-5  # a small value to avoid division by zero\n",
    "weight_positive = total_samples / (weight2 * (torch.sum(targets == 1) + epsilon))\n",
    "weight_negative = total_samples / (weight1 * (torch.sum(targets == 0) + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=5, alpha=0.5):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        bce_loss = torch.nn.functional.binary_cross_entropy_with_logits(output, target, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = (self.alpha * (1 - pt) ** self.gamma * bce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    " \n",
    "def model_train(model, X_train, y_train, X_val, y_val, alpha,gamma,weight1=1, weight2=1):\n",
    "    # loss function and optimizer\n",
    "    # Assuming you have your predictions and targets\n",
    "\n",
    "\n",
    "    # Create a weight tensor\n",
    "    # Generate random indices\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "    n_epochs = 1000   # number of epochs to run\n",
    "    batch_size = 5  # size of each batch :20\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "    best_kappa=-1\n",
    "    best_spec=-1\n",
    " \n",
    "    for epoch in range(n_epochs):\n",
    "        indices = torch.randperm(len(y_train))\n",
    "\n",
    "        # Shuffle both tensors using the same indices\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                targets = y_batch\n",
    "\n",
    "                # Calculate the class weights based on the class distribution\n",
    "                total_samples = len(targets)\n",
    "                epsilon = 1e-5  # a small value to avoid division by zero\n",
    "                #weight_positive = total_samples / (weight2 * (torch.sum(targets == 1) + epsilon))\n",
    "                #weight_negative = total_samples / (weight1 * (torch.sum(targets == 0) + epsilon))\n",
    "                #weights = torch.where(targets == 1, torch.tensor(weight_positive), torch.tensor(weight_negative))\n",
    "\n",
    "                \n",
    "                #return(weights,y_batch,y_pred)\n",
    "                #loss = torch.nn.functional.binary_cross_entropy_with_logits(y_pred, y_batch, weight=weights )\n",
    "                loss = FocalLoss(gamma=gamma,alpha=alpha)(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        kappa=cohen_kappa_score(y_pred.round().detach().numpy()[:,0], y_test.detach().numpy()[:,0])\n",
    "        true_negatives = np.sum((y_test.detach().numpy()[:,0] == 0) & (y_pred.round().detach().numpy()[:,0] == 0))\n",
    "        false_positives = np.sum((y_test.detach().numpy()[:,0] == 0) & (y_pred.round().detach().numpy()[:,0] == 1))\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "        if kappa > best_kappa:\n",
    "            best_acc = acc\n",
    "            best_kappa=kappa\n",
    "            best_spec=specificity\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_kappa,best_spec,best_acc,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=[i/10 for i in range(1,10)]\n",
    "gamma=[i/100 for i in range(500,700,5)]\n",
    "pbar = tqdm.tqdm(total=len(alpha)*len(gamma))\n",
    "output=pd.DataFrame(columns=[\"alpha\",\"gamma\",\"kappa\",\"specificity\",\"accuracy\"])\n",
    "for a in alpha:\n",
    "    for g in gamma:\n",
    "        model = Deep()\n",
    "        best_kappa,best_spec,best_acc,model = model_train(model, X_train, y_train, X_test, y_test,alpha=a,gamma=g)\n",
    "        print(\"Accuracy (deep): %.2f\" % best_acc)\n",
    "        print(\"Kappa (deep): %.2f\" % best_kappa)\n",
    "        print(\"Specificity (deep): %.2f\" % best_spec)\n",
    "        print(\"alpha: %.2f\" % a)\n",
    "        print(\"gamma: %.2f\" % g)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        output=output.append({\"alpha\":a,\"gamma\":g,\"kappa\":best_kappa,\"specificity\":best_spec,\"accuracy\":best_acc},ignore_index=True)\n",
    "        #save csv\n",
    "        output.to_csv(\"output6.csv\",index=False)\n",
    "        pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deep()\n",
    "best_kappa,best_spec,best_acc,model = model_train(model, X_train, y_train, X_test, y_test,alpha=0.2,gamma=5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11202231674031227, 0.6842105263157895, 0.6639118194580078)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_kappa,best_spec,best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to file\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "import tqdm\n",
    "\n",
    "weight2_range=[i/2000 for i in range(400,300,-1)]\n",
    "weight1_range=[i/10 for i in range(1,20,1)]\n",
    "print(len(weight1_range),len(weight2_range))\n",
    "pbar = tqdm.tqdm(total=len(weight1_range)*len(weight2_range))\n",
    "for i in weight1_range:\n",
    "    stop=0\n",
    "    for j in weight2_range:\n",
    "        \n",
    "        model = Deep()\n",
    "        best_kappa,best_acc,model = model_train(model, X_train, y_train, X_test, y_test,weight1=i,weight2=j)\n",
    "        print(\"Accuracy (deep): %.2f\" % best_acc)\n",
    "        print(\"Kappa (deep): %.2f\" % best_kappa)\n",
    "        model.eval()\n",
    "        outputs = model(X_test)\n",
    "        y_pred = outputs.round().detach().numpy()\n",
    "        \n",
    "\n",
    "        kappa=cohen_kappa_score(y_pred[:,0], y_test.detach().numpy()[:,0])\n",
    "        if kappa > best_kappa:\n",
    "            best_kappa=kappa\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            best_weight1=i\n",
    "            best_weight2=j\n",
    "            print(\"best kappa:\",best_kappa,\"best weight1:\",best_weight1,\"best weight2:\",best_weight2)\n",
    "            stop=0\n",
    "        else:\n",
    "            stop+=1\n",
    "            if stop>3:\n",
    "                break\n",
    "                \n",
    "        pbar.update(1)\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deep()\n",
    "best_kappa,best_acc,model = model_train(model, X_train, y_train, X_test, y_test,weight1=i,weight2=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kappa,best_weight1,best_weight2 #with dropout 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kappa,best_weight1,best_weight2 #without dropout 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kappa,best_weight1,best_weight2 #without dropout 0.2, larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kappa,best_weight1,best_weight2 #without dropout 0.2, larger model new weight range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "predicted_classes = (outputs > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Your list of values\n",
    "my_list = predicted_classes[:,0].tolist()\n",
    "\n",
    "# Count the occurrences of each value\n",
    "value_counts = Counter(my_list)\n",
    "\n",
    "# Print the result\n",
    "for value, count in value_counts.items():\n",
    "    print(f\"Value {value} appears {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
